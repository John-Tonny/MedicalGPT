# !/bin/bash

python inference.py --model_type chatglm --base_model /opt/chatglm2-6b --lora_model outputs-pt-bloom-v1 --interactive
